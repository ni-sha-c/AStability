{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import math, random, sys, os, time, pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Execute this for CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = '/gstore/project/prescient/data/loukasa1/alg-stability/model_weights'\n",
    "focus_on   = 'features.0.weight'\n",
    "data       = 'cifar'\n",
    "\n",
    "epochs_all, weights_all, loss_all, accuracy_all, accuracy_test_all, noise_all = [], [], [], [], [], []\n",
    "\n",
    "for folder in os.listdir(models_dir):\n",
    "        \n",
    "    if 'cifar10-vgg16' not in folder: continue\n",
    "    if '20.04' in folder: continue\n",
    "    if '21.04' in folder: continue\n",
    "    if 'wd' not in folder: continue \n",
    "        \n",
    "    model_dir = os.path.join(models_dir, folder)\n",
    "    models = [m for m in os.listdir(model_dir) if os.path.isfile(os.path.join(model_dir, m))]\n",
    "\n",
    "    print(model_dir)\n",
    "    if 'noise:0.25' in model_dir: noise_all.append(0.25) \n",
    "    else: noise_all.append(0) \n",
    "\n",
    "    epochs, weights, loss, accuracy, accuracy_test = [], [], [], [], []\n",
    "\n",
    "    for model in models:    \n",
    "        dummy = torch.load(os.path.join(model_dir, model))\n",
    "        epochs.append(dummy['epoch'])\n",
    "        weights.append(dummy['model_state_dict'][focus_on].detach().cpu().numpy())\n",
    "\n",
    "        if 'loss' in dummy.keys(): \n",
    "            loss.append(dummy['loss'])\n",
    "        else: \n",
    "            loss.append(np.nan)\n",
    "\n",
    "        if 'accuracy' in dummy.keys(): \n",
    "            accuracy.append(dummy['accuracy'].detach().cpu().numpy())\n",
    "        else: \n",
    "            accuracy.append(np.nan)\n",
    "            \n",
    "        if 'accuracy_test' in dummy.keys(): \n",
    "            accuracy_test.append(dummy['accuracy_test'].detach().cpu().numpy())\n",
    "        else: \n",
    "            accuracy_test.append(np.nan)\n",
    "            \n",
    "    idx = np.argsort(np.array(epochs))\n",
    "    weights  = np.array([weights[i] for i in idx])\n",
    "    epochs   = np.array([epochs[i] for i in idx])\n",
    "    loss     = np.array([loss[i] for i in idx])\n",
    "    accuracy = np.array([accuracy[i] for i in idx])\n",
    "    accuracy_test = np.array([accuracy_test[i] for i in idx])\n",
    "\n",
    "    weights_all.append(weights)\n",
    "    epochs_all.append(epochs)\n",
    "    loss_all.append(loss)\n",
    "    accuracy_all.append(accuracy)\n",
    "    accuracy_test_all.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in dummy['model_state_dict'].keys(): print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_start, min_n_epochs = 400, 4000 \n",
    "X = np.array([weights_all[i][j].reshape(-1) for i,epochs in enumerate(epochs_all) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "obs_train = np.array([loss_all[i][j] for i,epochs in enumerate(epochs_all) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "obs_test = np.array([accuracy_test_all[i][j] for i,epochs in enumerate(epochs_all) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "e = np.array([epochs_all[i][j] for i,epochs in enumerate(epochs_all) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "r = np.array([i for i,epochs in enumerate(epochs_all) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "factor = np.array([noise_all[i] for i,epochs in enumerate(epochs_all) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "\n",
    "X.shape, obs_train.shape, obs_test.shape, e.shape, r.shape, factor.shape\n",
    "obs, obs_names = [obs_train,obs_test,e], ['log(loss)', 'test accuracy', 'epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Execute this for WIKITEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = '/gstore/scratch/u/loukasa1/alg-stability/model_weights' # TODO: change this \n",
    "focus_on   = 'transformer_encoder.layers.0.linear1.weight'\n",
    "data       = 'wiki'\n",
    "\n",
    "epochs_all, weights_all, loss_all, loss_val_all, loss_test_all, prc_all = [], [], [], [], [], []\n",
    "\n",
    "for folder in os.listdir(models_dir):\n",
    "\n",
    "    if ('wiki' not in folder): continue \n",
    "                \n",
    "    model_dir = os.path.join(models_dir, folder)\n",
    "    models = [m for m in os.listdir(model_dir) if os.path.isfile(os.path.join(model_dir, m))]\n",
    "\n",
    "    print(model_dir)\n",
    "\n",
    "    if 'prc:0.1' in model_dir: prc_all.append(0.1)\n",
    "    elif 'prc:0.01' in model_dir: prc_all.append(0.01)\n",
    "    elif 'prc:0.3' in model_dir: prc_all.append(0.3)\n",
    "    else: prc_all.append(1)\n",
    "        \n",
    "    epochs, weights, loss, loss_val, loss_test = [], [], [], [], []\n",
    "\n",
    "    for model in models:    \n",
    "        dummy = torch.load(os.path.join(model_dir, model))\n",
    "        epochs.append(dummy['epoch'])\n",
    "        weights.append(dummy[focus_on].detach().cpu().numpy())\n",
    "\n",
    "        if 'loss' in dummy.keys(): \n",
    "            loss.append(dummy['loss'])\n",
    "        else: \n",
    "            loss.append(np.nan)\n",
    "\n",
    "        if 'loss_val' in dummy.keys(): \n",
    "            loss_val.append(dummy['loss_val'])\n",
    "        else: \n",
    "            loss_val.append(np.nan)\n",
    "            \n",
    "        if 'loss_test' in dummy.keys(): \n",
    "            loss_test.append(dummy['loss_test'])\n",
    "        else: \n",
    "            loss_test.append(np.nan)\n",
    "            \n",
    "    idx = np.argsort(np.array(epochs))\n",
    "    weights   = np.array([weights[i] for i in idx])\n",
    "    epochs    = np.array([epochs[i] for i in idx])\n",
    "    loss      = np.array([loss[i] for i in idx])\n",
    "    loss_val  = np.array([loss_val[i] for i in idx])\n",
    "    loss_test = np.array([loss_test[i] for i in idx])\n",
    "\n",
    "    weights_all.append(weights)\n",
    "    epochs_all.append(epochs)\n",
    "    loss_all.append(loss)\n",
    "    loss_val_all.append(loss_val)\n",
    "    loss_test_all.append(loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_start, min_n_epochs = 0, 0 \n",
    "X = np.array([weights_all[i][j].reshape(-1) for i,epochs in enumerate(epochs_all) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "obs_train = np.array([loss_all[i][j] for i,epochs in enumerate(epochs_all) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "obs_test  = np.array([loss_test_all[i][j] for i,epochs in enumerate(epochs_all) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "e         = np.array([epochs_all[i][j]*101544324*0.01*prc_all[i] for i,epochs in enumerate(epochs_all) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "r         = np.array([i for i,epochs in enumerate(epochs_all) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "factor    = np.array([prc_all[i] for i,epochs in enumerate(epochs_all) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "\n",
    "X.shape, obs_train.shape, obs_test.shape, e.shape, r.shape, factor.shape\n",
    "obs, obs_names = [obs_train,obs_test,e], ['loss', 'test loss', 'log(epoch)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PCA (execute for both cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=40).fit(X)\n",
    "plt.plot(np.log(pca.explained_variance_))\n",
    "U = pca.components_\n",
    "Xpca = X @ U.T\n",
    "X.shape, U.shape, Xpca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualization based on random directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data == 'cifar'\n",
    "\n",
    "n_iters = 5\n",
    "\n",
    "fig = plt.figure(figsize=(3*10, 9*n_iters), facecolor=(1,1,1))\n",
    "for it in range(n_iters): \n",
    "    \n",
    "    v1 = np.random.randn(len(weights_all[0][0].reshape(-1))); v1 = v1 @ U.T; v1 /= np.linalg.norm(v1)\n",
    "    v2 = np.random.randn(len(weights_all[0][0].reshape(-1))); v2 = v2 @ U.T; v2 /= np.linalg.norm(v2)\n",
    "\n",
    "    Xe = np.zeros((X.shape[0], 2))\n",
    "    for i in range(X.shape[0]):\n",
    "        Xe[i,0] = np.sum(Xpca[i,:] * v1)\n",
    "        Xe[i,1] = np.sum(Xpca[i,:] * v2)\n",
    "\n",
    "    for i,x,name in zip([1,2,3], obs, obs_names):\n",
    "        ax = fig.add_subplot(n_iters,3,it*3 + i)\n",
    "        for j in np.unique(r):\n",
    "            mask = np.where(r==j)[0]\n",
    "            if noise_all[int(j)] == 0: \n",
    "                sc = ax.plot(Xe[mask, 0], Xe[mask, 1], 'k-', alpha=0.5) \n",
    "            else: \n",
    "                sc = ax.plot(Xe[mask, 0], Xe[mask, 1], 'y-', alpha=0.5) \n",
    "        if 'log' in name: \n",
    "            sc = ax.scatter(Xe[:, 0], Xe[:, 1], c=np.log(0.0000+x), cmap=plt.cm.Spectral.reversed(), marker='o', alpha=1)\n",
    "        else: \n",
    "            sc = ax.scatter(Xe[:, 0], Xe[:, 1], c=x, cmap=plt.cm.Spectral.reversed(), marker='o', alpha=1)\n",
    "        \n",
    "        plt.colorbar(sc);\n",
    "        ax.set_title(name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WIKITEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data == 'wiki'\n",
    "\n",
    "n_iters = 5\n",
    "\n",
    "fig = plt.figure(figsize=(3*10, 9*n_iters), facecolor=(1,1,1))\n",
    "for it in range(n_iters): \n",
    "    \n",
    "    v1 = np.random.randn(len(weights_all[0][0].reshape(-1))); v1 = v1 @ U.T; v1 /= np.linalg.norm(v1)\n",
    "    v2 = np.random.randn(len(weights_all[0][0].reshape(-1))); v2 = v2 @ U.T; v2 /= np.linalg.norm(v2)\n",
    "\n",
    "    Xe = np.zeros((X.shape[0], 2))\n",
    "    for i in range(X.shape[0]):\n",
    "        Xe[i,0] = np.sum(Xpca[i,:] * v1)\n",
    "        Xe[i,1] = np.sum(Xpca[i,:] * v2)\n",
    "\n",
    "    for i,x,name in zip([1,2,3], obs, obs_names):\n",
    "        ax = fig.add_subplot(n_iters,3,it*3 + i)\n",
    "        for j in np.unique(r):\n",
    "            mask = np.where(r==j)[0]\n",
    "            sc = ax.plot(Xe[mask, 0], Xe[mask, 1], 'k-', alpha=0.1, linewidth=2) \n",
    "#             if prc_all[int(j)] == 0.01: \n",
    "#                 sc = ax.plot(Xe[mask, 0], Xe[mask, 1], 'r-', alpha=0.31, label=' 1%', linewidth=5) \n",
    "#             elif prc_all[int(j)] == 0.1: \n",
    "#                 sc = ax.plot(Xe[mask, 0], Xe[mask, 1], 'm-', alpha=0.31, label='10%', linewidth=5) \n",
    "#             else: \n",
    "#                 sc = ax.plot(Xe[mask, 0], Xe[mask, 1], 'g-', alpha=0.31, label='30%', linewidth=5) \n",
    "        if 'log' in name: \n",
    "            sc = ax.scatter(Xe[:, 0], Xe[:, 1], c=np.log(0.0000+x), cmap=plt.cm.Spectral.reversed(), marker='o', alpha=1, s=50)\n",
    "        else: \n",
    "            sc = ax.scatter(Xe[:, 0], Xe[:, 1], c=x, cmap=plt.cm.Spectral.reversed(), marker='o', alpha=1, s=50, vmin=2, vmax=14)\n",
    "        \n",
    "        plt.colorbar(sc);\n",
    "        ax.set_title(name);\n",
    "#         ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization based on t-SNE (CIFAR & WIKITEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xe = TSNE(n_components=2, perplexity=10).fit_transform(Xpca)\n",
    "fig = plt.figure(figsize=(3*8, 6))\n",
    "\n",
    "for i,x,name in zip([1,2,3], obs, obs_names):\n",
    "    ax = fig.add_subplot(1,3,i)\n",
    "    for j in np.unique(r):\n",
    "        mask = np.where(r==j)[0]\n",
    "#         if noise_all[int(j)] == 0: \n",
    "#             sc = ax.plot(Xe[mask, 0], Xe[mask, 1], 'k-', alpha=0.5) \n",
    "#         else: \n",
    "#             sc = ax.plot(Xe[mask, 0], Xe[mask, 1], 'y-', alpha=0.5) \n",
    "            \n",
    "    if 'log' in name: \n",
    "        sc = ax.scatter(Xe[:, 0], Xe[:, 1], c=np.log(0.0000+x), cmap=plt.cm.Spectral.reversed(), marker='o', alpha=1)\n",
    "    else: \n",
    "        sc = ax.scatter(Xe[:, 0], Xe[:, 1], c=x, cmap=plt.cm.Spectral.reversed(), marker='o', alpha=1)\n",
    "\n",
    "    plt.colorbar(sc);\n",
    "    ax.set_title(name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization based on principal components (CIFAR & WIKITEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(-1,len(epochs_all)): \n",
    "    \n",
    "    if i == -1: \n",
    "        T = X.copy()\n",
    "    else:\n",
    "        epochs = epochs_all[i]\n",
    "        T = np.array([weights_all[i][j].reshape(-1) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "\n",
    "    if T.shape[0] == 0: continue\n",
    "\n",
    "    mean = np.mean(T, axis=0)\n",
    "    T -= np.repeat(mean.reshape((1,-1)), T.shape[0], axis=0)\n",
    "    eigvalues, eigvectors = np.linalg.eigh(T.T @ T)\n",
    "\n",
    "    v1 = eigvectors[:,-1]\n",
    "    v2 = eigvectors[:,-2]\n",
    "\n",
    "    Xe = np.zeros((X.shape[0], 2))\n",
    "    for i in range(X.shape[0]):\n",
    "        Xe[i,0] = np.sum(X[i,:] * v1)\n",
    "        Xe[i,1] = np.sum(X[i,:] * v2)\n",
    "\n",
    "    fig = plt.figure(figsize=(3*8, 6))\n",
    "\n",
    "    for i,x,name in zip([1,2,3], obs, obs_names):\n",
    "        ax = fig.add_subplot(1,3,i)\n",
    "        for j in np.unique(r):\n",
    "            mask = np.where(r==j)[0]\n",
    "            sc = ax.plot(Xe[mask, 0], Xe[mask, 1], 'k-', alpha=0.4) \n",
    "        if 'log' in name: \n",
    "            sc = ax.scatter(Xe[:, 0], Xe[:, 1], c=np.log(0.0000+x), cmap=plt.cm.Spectral.reversed(), marker='o', alpha=1)\n",
    "        else: \n",
    "            sc = ax.scatter(Xe[:, 0], Xe[:, 1], c=x, cmap=plt.cm.Spectral.reversed(), marker='o', alpha=1)\n",
    "\n",
    "        plt.colorbar(sc);\n",
    "        ax.set_title(name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How they move w.r.t. the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3*8, 6))\n",
    "\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "ax2 = fig.add_subplot(1,3,2)\n",
    "ax3 = fig.add_subplot(1,3,3)\n",
    "\n",
    "for i in np.arange(len(epochs_all)): \n",
    "    \n",
    "    epochs = epochs_all[i]\n",
    "    T = np.array([weights_all[i][j].reshape(-1) for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "    e = np.array([epoch for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "    l = np.array([loss_all[i][j] for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "    a = np.array([accuracy_all[i][j] for j,epoch in enumerate(epochs) if max(epochs) > min_n_epochs and epoch >= epoch_start]).astype(np.float)\n",
    "\n",
    "    n_epochs = T.shape[0]\n",
    "    \n",
    "    if n_epochs == 0: continue\n",
    "\n",
    "    mean = np.mean(T, axis=0)\n",
    "    dist = np.zeros(n_epochs)\n",
    "    for j in range(n_epochs): dist[j] = np.linalg.norm(T[j,:] - mean)\n",
    "\n",
    "    for x,name,ax in zip([l,a,e], obs, obs_names):\n",
    "        ax.plot(e, dist, 'k-', alpha=0.4) \n",
    "        if 'log(loss)' in name: \n",
    "            sc = ax.scatter(e, dist, c=np.log(0.0000+x), cmap=plt.cm.Spectral.reversed(), marker='o', alpha=1, vmin=-3, vmax=-1)\n",
    "        elif 'accuracy' in name:  \n",
    "            sc = ax.scatter(e, dist, c=x, cmap=plt.cm.Spectral.reversed(), marker='o', alpha=1, vmin=0.94, vmax=0.97)\n",
    "        elif 'epoch' in name:  \n",
    "            sc = ax.scatter(e, dist, c=x, cmap=plt.cm.Spectral.reversed(), marker='o', alpha=1, vmin=1000, vmax=5000)\n",
    "\n",
    "        if i == len(epochs_all)-1: \n",
    "            plt.colorbar(sc);\n",
    "            ax.set_title(name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,epochs in enumerate(epochs_all):\n",
    "    norm = np.zeros(len(epochs)) \n",
    "    for j,epoch in enumerate(epochs): \n",
    "        norm[j] = np.linalg.norm(weights_all[i][j].reshape(-1))\n",
    "\n",
    "    plt.plot(epochs, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyro",
   "language": "python",
   "name": "pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
